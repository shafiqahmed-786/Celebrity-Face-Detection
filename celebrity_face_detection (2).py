# -*- coding: utf-8 -*-
"""Celebrity_Face_Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1K7EU_QYCf7K-srucirNXvPCXlNb6AJ7c
"""

from google.colab import files
uploaded = files.upload()

import zipfile
import io

# assuming your file name is exactly this
zip_file = 'archive (7).zip'

with zipfile.ZipFile(zip_file, 'r') as zip_ref:
    zip_ref.extractall('extracted_data')  # this will extract files into this folder

import os
import pandas as pd

# Set base folder path where images were extracted
base_path = 'extracted_data/Celebrity Faces Dataset'

image_paths = []
labels = []

# Walk through each celebrity folder
for label in os.listdir(base_path):
    folder_path = os.path.join(base_path, label)
    if os.path.isdir(folder_path):
        for file in os.listdir(folder_path):
            if file.lower().endswith(('.jpg', '.jpeg', '.png')):
                image_paths.append(os.path.join(folder_path, file))
                labels.append(label)

# Create the DataFrame
df = pd.DataFrame({
    'image_path': image_paths,
    'label': labels
})

df.head()

import os

# List files and directories in the extracted_data folder
print(os.listdir('extracted_data'))

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import cv2
import matplotlib
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns

df.shape

img = cv2.imread(df['image_path'][0])
img.shape

plt.imshow(img)

gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
plt.imshow(gray, cmap='gray')

gray.shape

gray

face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

pip install opencv-contrib-python

face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')

faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)
faces

(x,y,w,h) = faces[0]
x,y,w,h

# Reload the original image
img = cv2.imread(df['image_path'][0])

face_img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0), 2)
# Convert the image from BGR to RGB before displaying with matplotlib
face_img_rgb = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)
plt.imshow(face_img_rgb)

cv2.destroyAllWindows()
for (x,y,w,h) in faces:
    face_img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0), 2)
    roi_gray = gray[y:y+h, x:x+w]
    roi_color = face_img[y:y+h, x:x+w]
    eyes = eye_cascade.detectMultiScale(roi_gray)
    for (ex,ey,ew,eh) in eyes:
        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)

plt.figure()
plt.imshow(face_img, cmap='gray')
plt.show()

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
plt.imshow(roi_color, cmap='gray')

def get_cropped_image_if_2_eyes(image_path):
    img = cv2.imread(image_path)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray, 1.3, 5)
    for (x,y,w,h) in faces:
      roi_gray = gray[y:y+h, x:x+w]
      roi_color = img[y:y+h, x:x+w]
      eyes = eye_cascade.detectMultiScale(roi_gray)
      if len(eyes) >= 2:
        return roi_color
    return None

original_image = get_cropped_image_if_2_eyes(df['image_path'][0])
plt.imshow(original_image)

path_to_data = "./extracted_data/Celebrity Faces Dataset"
path_to_cr_data = "./extracted_data/Celebrity Faces Dataset/cropped"

import os
img_dirs = []
for entry in os.scandir(path_to_data):
    if entry.is_dir():
        img_dirs.append(entry.path)

img_dirs

import shutil
if os.path.exists(path_to_cr_data):
    shutil.rmtree(path_to_cr_data)
os.mkdir(path_to_cr_data)

import cv2
import os
import numpy as np

# Define the function to crop images with two eyes detected
def get_cropped_image_if_2_eyes(image_path):
    img = cv2.imread(image_path)
    if img is None:
        return None
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
    eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')
    if face_cascade.empty() or eye_cascade.empty():
        return None
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)
    for (x, y, w, h) in faces:
        roi_gray = gray[y:y+h, x:x+w]
        roi_color = img[y:y+h, x:x+w]
        eyes = eye_cascade.detectMultiScale(roi_gray)
        if len(eyes) >= 2:
            return roi_color
    return None

# Your code with fixes
cropped_image_dirs = []
celebrity_file_names_dict = {}

for img_dir in img_dirs:  # Ensure img_dirs is defined
    count = 1
    celebrity_name = img_dir.split('/')[-1]
    print(celebrity_name)

    celebrity_file_names_dict[celebrity_name] = []

    for entry in os.scandir(img_dir):
        roi_color = get_cropped_image_if_2_eyes(entry.path)
        if roi_color is not None:
            cropped_folder = path_to_cr_data + "/" + celebrity_name  # Ensure path_to_cr_data is defined
            if not os.path.exists(cropped_folder):
                os.makedirs(cropped_folder)
                cropped_image_dirs.append(cropped_folder)
                print("Generating cropped images in folder: ", cropped_folder)

            cropped_file_name = celebrity_name + str(count) + ".png"
            cropped_file_path = cropped_folder + "/" + cropped_file_name  # Fixed variable name
            cv2.imwrite(cropped_file_path, roi_color)
            celebrity_file_names_dict[celebrity_name].append(cropped_file_path)
            count += 1

import numpy as np
import pywt
import cv2

def w2d(img, mode='haar', level=1):
    imArray = img
    #Datatype conversions
    #convert to grayscale
    imArray = cv2.cvtColor( imArray,cv2.COLOR_BGR2GRAY)
    #Convert to float
    imArray =  np.float32(imArray)
    imArray /= 255;
    # compute coefficients
    coeffs=pywt.wavedec2(imArray, mode, level=level)
    #Process coefficients
    coeffs_H=list(coeffs)
    coeffs_H[0] *= 0;
    #reconstruction
    imArray_H=pywt.waverec2(coeffs_H, mode);
    imArray_H *= 255;
    imArray_H =  np.uint8(imArray_H)
    return imArray_H

# Get the path to the first cropped image of the first celebrity
first_celebrity = list(celebrity_file_names_dict.keys())[0]
first_image_path = celebrity_file_names_dict[first_celebrity][0]

# Load the cropped image
cropped_img = cv2.imread(first_image_path)

# Ensure the image is not empty before processing
if cropped_img is not None:
    im_har = w2d(cropped_img,'db1',5)
    plt.imshow(im_har, cmap='gray')
else:
    print(f"Could not load image from path: {first_image_path}")

celebrity_file_names_dict

class_dict = {}
count = 0
for celebrity_name in celebrity_file_names_dict.keys():
    class_dict[celebrity_name] = count
    count = count + 1
class_dict

x = []
y = []
for celebrity_name, training_files in celebrity_file_names_dict.items():
    for training_image in training_files:
        img = cv2.imread(training_image)
        if img is None:
            continue
        scalled_raw_img = cv2.resize(img, (32, 32))
        img_har = w2d(img,'db1',5)
        scalled_img_har = cv2.resize(img_har, (32, 32))
        combined_img = np.vstack((scalled_raw_img.reshape(32 * 32 * 3, 1), scalled_img_har.reshape(32 * 32, 1)))
        x.append(combined_img)
        y.append(class_dict[celebrity_name])

len(x)

X = np.array(x).reshape(len(x),4096).astype(float)
X.shape

from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.pipeline import Pipeline

x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=0)
pipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC(kernel = 'rbf', C = 10))])
pipe.fit(x_train, y_train)
pipe.score(x_test, y_test)

print(classification_report(y_test, pipe.predict(x_test)))

"""GridSearch"""

from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import GridSearchCV
import pandas as pd
import numpy as np

# Assume x_train, y_train are embeddings from DeepFace
model_params = {
    'svm': {
        'model': SVC(probability=True),
        'params': {
            'svc__C': [0.1, 1, 10, 100],
            'svc__kernel': ['rbf', 'linear'],
            'svc__gamma': ['scale', 'auto', 0.001, 0.01]
        }
    },
    'random_forest': {
        'model': RandomForestClassifier(),
        'params': {
            'randomforestclassifier__n_estimators': [10, 50, 100],
            'randomforestclassifier__max_depth': [None, 10, 20],
            'randomforestclassifier__min_samples_split': [2, 5]
        }
    },
    'logistic_regression': {
        'model': LogisticRegression(solver='liblinear'),
        'params': {
            'logisticregression__C': [0.1, 1, 5, 10],
            'logisticregression__penalty': ['l1', 'l2']
        }
    },
    'knn': {
        'model': KNeighborsClassifier(),
        'params': {
            'kneighborsclassifier__n_neighbors': [3, 5, 7],
            'kneighborsclassifier__weights': ['uniform', 'distance']
        }
    }
}

scores = []
best_estimators = {}
for algo, mp in model_params.items():
    pipe = make_pipeline(StandardScaler(), mp['model'])
    clf = GridSearchCV(pipe, mp['params'], cv=5, return_train_score=False)
    clf.fit(x_train, y_train)
    scores.append({
        'model': algo,
        'best_score': clf.best_score_,
        'best_params': clf.best_params_
    })
    best_estimators[algo] = clf.best_estimator_

df = pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])
print(df)

pip install deepface

from deepface import DeepFace
import cv2
import numpy as np

def extract_embeddings(image_path):
    try:
        # Load and preprocess image
        img = cv2.imread(image_path)
        if img is None:
            print(f"Warning: Could not load image from {image_path}")
            return None
        # Extract embeddings using a pre-trained model (e.g., VGGFace)
        # DeepFace.represent returns a list of dictionaries, we need the 'embedding' value
        embeddings_list = DeepFace.represent(image_path, model_name='Facenet', enforce_detection=False)
        if embeddings_list and 'embedding' in embeddings_list[0]:
            return np.array(embeddings_list[0]['embedding'])
        else:
            print(f"Warning: Could not extract embedding from {image_path}")
            return None
    except Exception as e:
        print(f"Error extracting embedding from {image_path}: {e}")
        return None

# Assuming celebrity_file_names_dict from your earlier code
embeddings = []
labels = []
for celebrity_name, image_paths in celebrity_file_names_dict.items():
    for path in image_paths:
        emb = extract_embeddings(path)
        if emb is not None:
            embeddings.append(emb)
            labels.append(celebrity_name)

x_train = np.array(embeddings)
y_train = np.array(labels)

print(f"Shape of x_train: {x_train.shape}")
print(f"Length of y_train: {len(y_train)}")

from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import GridSearchCV

model_params = {
    'svm': {
        'model': SVC(probability=True),
        'params': {
            'svc__C': [0.1, 1, 10, 100, 1000],
            'svc__kernel': ['rbf', 'linear'],
            'svc__gamma': ['scale', 'auto', 0.001, 0.01, 0.1]
        }
    },
    'random_forest': {
        'model': RandomForestClassifier(),
        'params': {
            'randomforestclassifier__n_estimators': [10, 50, 100, 200],
            'randomforestclassifier__max_depth': [None, 10, 20, 30],
            'randomforestclassifier__min_samples_split': [2, 5, 10]
        }
    },
    'logistic_regression': {
        'model': LogisticRegression(solver='liblinear'),  # Remove deprecated multi_class
        'params': {
            'logisticregression__C': [0.1, 1, 5, 10, 100],
            'logisticregression__penalty': ['l1', 'l2']
        }
    }
}

scores = []
best_estimators = {}
for algo, mp in model_params.items():
    pipe = make_pipeline(StandardScaler(), mp['model'])
    clf = GridSearchCV(pipe, mp['params'], cv=5, return_train_score=False)
    clf.fit(x_train, y_train)
    scores.append({
        'model': algo,
        'best_score': clf.best_score_,
        'best_params': clf.best_params_
    })
    best_estimators[algo] = clf.best_estimator_

df = pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])
print(df)

!pip install joblib
import joblib
#save the model as a pickle in a file
joblib.dump(best_estimators['svm'], 'saved_model.pkl')

import json
with open("class_dictionary.json","w") as f:
    f.write(json.dumps(class_dict))